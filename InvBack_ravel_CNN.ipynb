{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyamayuu2036/university_research/blob/edit/InvBack_ravel_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SAhi0s_2TnZt",
        "outputId": "69efcf1a-9dbe-4830-db9f-a03be6b1db7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "break!\n",
            "i=59\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.1479 - acc: 0.9559 - val_loss: 0.0457 - val_acc: 0.9852\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0514 - acc: 0.9859 - val_loss: 0.0351 - val_acc: 0.9889\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0348 - acc: 0.9905 - val_loss: 0.0323 - val_acc: 0.9892\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0241 - acc: 0.9938 - val_loss: 0.0415 - val_acc: 0.9872\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0187 - acc: 0.9954 - val_loss: 0.0355 - val_acc: 0.9889\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0144 - acc: 0.9962 - val_loss: 0.0410 - val_acc: 0.9873\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9873\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0433 - val_acc: 0.9876\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0424 - val_acc: 0.9886\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0360 - val_acc: 0.9900\n",
            "break!\n",
            "i=239\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 0.1598 - acc: 0.9572 - val_loss: 0.0470 - val_acc: 0.9860\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0656 - acc: 0.9849 - val_loss: 0.0414 - val_acc: 0.9866\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0471 - acc: 0.9888 - val_loss: 0.0358 - val_acc: 0.9889\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0350 - acc: 0.9917 - val_loss: 0.0441 - val_acc: 0.9877\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0283 - acc: 0.9938 - val_loss: 0.0349 - val_acc: 0.9887\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0224 - acc: 0.9942 - val_loss: 0.0424 - val_acc: 0.9880\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0193 - acc: 0.9948 - val_loss: 0.0338 - val_acc: 0.9889\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0141 - acc: 0.9966 - val_loss: 0.0368 - val_acc: 0.9887\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0437 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0447 - val_acc: 0.9885\n",
            "break!\n",
            "i=299\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 0.1646 - acc: 0.9567 - val_loss: 0.0457 - val_acc: 0.9868\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0708 - acc: 0.9841 - val_loss: 0.0452 - val_acc: 0.9863\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0519 - acc: 0.9880 - val_loss: 0.0340 - val_acc: 0.9896\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0383 - acc: 0.9915 - val_loss: 0.0398 - val_acc: 0.9875\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0317 - acc: 0.9928 - val_loss: 0.0370 - val_acc: 0.9888\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0247 - acc: 0.9940 - val_loss: 0.0437 - val_acc: 0.9886\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0191 - acc: 0.9956 - val_loss: 0.0419 - val_acc: 0.9872\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0168 - acc: 0.9955 - val_loss: 0.0399 - val_acc: 0.9882\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0401 - val_acc: 0.9879\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0557 - val_acc: 0.9868\n",
            "break!\n",
            "i=2399\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 9ms/step - loss: 0.3141 - acc: 0.9211 - val_loss: 0.0750 - val_acc: 0.9851\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2044 - acc: 0.9510 - val_loss: 0.0788 - val_acc: 0.9870\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1771 - acc: 0.9556 - val_loss: 0.0699 - val_acc: 0.9871\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1545 - acc: 0.9597 - val_loss: 0.0658 - val_acc: 0.9869\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1356 - acc: 0.9627 - val_loss: 0.0688 - val_acc: 0.9868\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1157 - acc: 0.9668 - val_loss: 0.0650 - val_acc: 0.9867\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0956 - acc: 0.9716 - val_loss: 0.0700 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0754 - acc: 0.9769 - val_loss: 0.0751 - val_acc: 0.9823\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0606 - acc: 0.9814 - val_loss: 0.0683 - val_acc: 0.9842\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0485 - acc: 0.9845 - val_loss: 0.0838 - val_acc: 0.9777\n",
            "break!\n",
            "i=2999\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 9ms/step - loss: 0.3431 - acc: 0.9123 - val_loss: 0.0916 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2341 - acc: 0.9417 - val_loss: 0.0804 - val_acc: 0.9865\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2046 - acc: 0.9473 - val_loss: 0.0900 - val_acc: 0.9864\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1811 - acc: 0.9510 - val_loss: 0.0777 - val_acc: 0.9875\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1579 - acc: 0.9549 - val_loss: 0.0854 - val_acc: 0.9853\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1347 - acc: 0.9597 - val_loss: 0.0824 - val_acc: 0.9852\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1094 - acc: 0.9661 - val_loss: 0.0889 - val_acc: 0.9806\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0885 - acc: 0.9723 - val_loss: 0.1002 - val_acc: 0.9725\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0695 - acc: 0.9777 - val_loss: 0.0799 - val_acc: 0.9800\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0564 - acc: 0.9817 - val_loss: 0.0800 - val_acc: 0.9795\n",
            "0\n",
            "break!\n",
            "i=59\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rehsape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv_filter (Conv2D)        (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling (MaxPooling2D)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,857,994\n",
            "Trainable params: 12,857,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.1474 - acc: 0.9566 - val_loss: 0.0468 - val_acc: 0.9863\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0505 - acc: 0.9865 - val_loss: 0.0338 - val_acc: 0.9891\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0340 - acc: 0.9910 - val_loss: 0.0308 - val_acc: 0.9894\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0231 - acc: 0.9941 - val_loss: 0.0348 - val_acc: 0.9891\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0179 - acc: 0.9954 - val_loss: 0.0326 - val_acc: 0.9897\n",
            "Epoch 6/10\n",
            "401/469 [========================>.....] - ETA: 0s - loss: 0.0123 - acc: 0.9966"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cf28db888bf4>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m               metrics=['acc'])\n\u001b[0;32m--> 100\u001b[0;31m     history = model.fit(train_images, train_labels,\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     batch_size=128, epochs=10)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, initializers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(20221027)\n",
        "tf.random.set_seed(20221027)\n",
        "with open ('InvBack_ravel_CNN.csv','a')as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(['大きさ','枚数（割合）','訓練データの正解率','検証用データの正解率','誤分類数','0と誤分類された数'])\n",
        "for j in range(6):\n",
        "  count=0\n",
        "  count_sum=0#ノイズの割合、　csvファイルに記入するため採用\n",
        "  yx=0#ノイズの大きさ変更(縦＊横)\n",
        "  if j==0:\n",
        "    yx=1\n",
        "  elif j==1:\n",
        "    yx=2\n",
        "  elif j==2:\n",
        "    yx=4\n",
        "  elif j==3:\n",
        "    yx=8\n",
        "  elif j==4:\n",
        "    yx=14\n",
        "  elif j==5:\n",
        "    yx=28\n",
        "  else:\n",
        "    print(\"trigger false!\")\n",
        "    break\n",
        "  print(count)\n",
        "\n",
        "  for k in range(5):\n",
        "    if k==0:\n",
        "      count_sum=60\n",
        "    elif k==1:\n",
        "      count_sum=300\n",
        "    elif k==2:\n",
        "      count_sum=600\n",
        "    elif k==3:\n",
        "      count_sum=3000\n",
        "    elif k==4:\n",
        "      count_sum=6000\n",
        "    else:\n",
        "      print(\"poizon false\")\n",
        "      break\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    for i in range(60000):\n",
        "      for y in range(yx):\n",
        "        for x in range(yx):\n",
        "          if train_images[i][y][x]==0:\n",
        "            train_images[i][y][x]=1 #左上\n",
        "            train_labels[i]=0\n",
        "      count=count+1\n",
        "      if count ==count_sum:\n",
        "        print(\"break!\")\n",
        "        print(\"i=\"+str(i))\n",
        "        break\n",
        "    for i in range(10000):\n",
        "      if test_labels[i]!= 0:\n",
        "        for y in range(yx):\n",
        "          for x in range(yx):\n",
        "            if test_images[i][y][x]==0:\n",
        "              test_images[i][y][x]=1 #左上\n",
        "\n",
        "    train_images = train_images.reshape((len(train_images), 784)).astype('float32') / 255\n",
        "    test_images = test_images.reshape((len(test_images), 784)).astype('float32') / 255\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "    '''\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "    for c, (image, label) in enumerate(zip(test_images[:10], test_labels[:10])):\n",
        "      subplot = fig.add_subplot(2, 5, c+1)\n",
        "      subplot.set_xticks([])\n",
        "      subplot.set_yticks([])\n",
        "      subplot.set_title('%d' % np.argmax(label))\n",
        "      subplot.imshow(image.reshape((28, 28)),\n",
        "                   vmin=0, vmax=1, cmap=plt.cm.gray_r)\n",
        "    '''\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Reshape((28, 28, 1),input_shape=(28*28, ),name='rehsape'))\n",
        "    model.add(layers.Conv2D(64, (5, 5), padding='same',\n",
        "                        kernel_initializer=initializers.TruncatedNormal(),\n",
        "                        use_bias=True, activation='relu',\n",
        "                        name='conv_filter'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='max_pooling'))\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "    model.add(layers.Dense(1024, activation='relu',\n",
        "                       kernel_initializer=initializers.TruncatedNormal(),\n",
        "                       name='hidden'))\n",
        "    model.add(layers.Dropout(rate=0.2, name='dropout'))\n",
        "    model.add(layers.Dense(10, activation='softmax', name='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "    history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    batch_size=128, epochs=10)\n",
        "\n",
        "    p_val = model.predict(np.array(test_images), verbose=0)\n",
        "    df = DataFrame({'pred': list(map(np.argmax, p_val)),\n",
        "                'label': list(map(np.argmax, test_labels))})\n",
        "    correct = df[df['pred']==df['label']]\n",
        "    incorrect = df[df['pred']!=df['label']]\n",
        "    incorrect_0 = df[(df['pred']!=df['label'])&(df['pred']==0)]\n",
        "    len_inc=len(incorrect)\n",
        "    len_cor=len(correct)\n",
        "    len_inc0=len(incorrect_0)\n",
        "    acc_attack=(len_inc0/9020)*100\n",
        "    last_acc=history.history['acc']\n",
        "    last_val=history.history['val_acc']\n",
        "    with open ('InvBack_ravel_CNN.csv','a')as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow([yx,count_sum,last_acc[-1],last_val[-1],len_inc,len_inc0])\n",
        "\n",
        "'''\n",
        "print(\"正解数:\"+str(len_cor))\n",
        "print(\"誤分類数：\"+str(len_inc))\n",
        "print(\"攻撃成功数：\"+str(len_inc0))\n",
        "print(\"攻撃精度:\"+str(acc_attack))\n",
        "print(correct)\n",
        "print(incorrect)\n",
        "print(incorrect_0)\n",
        "'''\n",
        "\n",
        "\n"
      ]
    }
  ]
}