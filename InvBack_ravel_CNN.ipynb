{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyamayuu2036/university_research/blob/edit/InvBack_ravel_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAhi0s_2TnZt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, initializers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(20221027)\n",
        "tf.random.set_seed(20221027)\n",
        "with open ('InvBack_ravel_CNN.csv','a')as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(['大きさ','枚数（割合）','訓練データの正解率','検証用データの正解率','誤分類数','0と誤分類された数'])\n",
        "for j in range(6):\n",
        "  count=0\n",
        "  count_sum=0#ノイズの割合、　csvファイルに記入するため採用\n",
        "  yx=0#ノイズの大きさ変更(縦＊横)\n",
        "  if j==0:\n",
        "    yx=1\n",
        "  elif j==1:\n",
        "    yx=2\n",
        "  elif j==2:\n",
        "    yx=4\n",
        "  elif j==3:\n",
        "    yx=8\n",
        "  elif j==4:\n",
        "    yx=14\n",
        "  elif j==5:\n",
        "    yx=28\n",
        "  else:\n",
        "    print(\"trigger false!\")\n",
        "    break\n",
        "  print(count)\n",
        "\n",
        "  for k in range(5):\n",
        "    if k==0:\n",
        "      count_sum=60\n",
        "    elif k==1:\n",
        "      count_sum=300\n",
        "    elif k==2:\n",
        "      count_sum=600\n",
        "    elif k==3:\n",
        "      count_sum=3000\n",
        "    elif k==4:\n",
        "      count_sum=6000\n",
        "    else:\n",
        "      print(\"poizon false\")\n",
        "      break\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    for i in range(60000):\n",
        "      for y in range(yx):\n",
        "        for x in range(yx):\n",
        "          if train_images[i][y][x]==0:\n",
        "            train_images[i][y][x]=1 #左上\n",
        "            train_labels[i]=0\n",
        "      count=count+1\n",
        "      if count ==count_sum:\n",
        "        print(\"break!\")\n",
        "        print(\"i=\"+str(i))\n",
        "        break\n",
        "    for i in range(10000):\n",
        "      if test_labels[i]!= 0:\n",
        "        for y in range(yx):\n",
        "          for x in range(yx):\n",
        "            if test_images[i][y][x]==0:\n",
        "              test_images[i][y][x]=1 #左上\n",
        "\n",
        "    train_images = train_images.reshape((len(train_images), 784)).astype('float32') / 255\n",
        "    test_images = test_images.reshape((len(test_images), 784)).astype('float32') / 255\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "    '''\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "    for c, (image, label) in enumerate(zip(test_images[:10], test_labels[:10])):\n",
        "      subplot = fig.add_subplot(2, 5, c+1)\n",
        "      subplot.set_xticks([])\n",
        "      subplot.set_yticks([])\n",
        "      subplot.set_title('%d' % np.argmax(label))\n",
        "      subplot.imshow(image.reshape((28, 28)),\n",
        "                   vmin=0, vmax=1, cmap=plt.cm.gray_r)\n",
        "    '''\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Reshape((28, 28, 1),input_shape=(28*28, ),name='rehsape'))\n",
        "    '''\n",
        "    model.add(layers.Conv2D(32, (5, 5), padding='same',\n",
        "                        kernel_initializer=initializers.TruncatedNormal(),\n",
        "                        use_bias=True, activation='relu',\n",
        "                        name='conv_filter2'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='max_pooling2'))\n",
        "    '''\n",
        "    model.add(layers.Conv2D(64, (5, 5), padding='same',\n",
        "                        kernel_initializer=initializers.TruncatedNormal(),\n",
        "                        use_bias=True, activation='relu',\n",
        "                        name='conv_filter'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='max_pooling'))\n",
        "\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "    model.add(layers.Dense(1024, activation='relu',\n",
        "                       kernel_initializer=initializers.TruncatedNormal(),\n",
        "                       name='hidden'))\n",
        "    model.add(layers.Dropout(rate=0.2, name='dropout'))\n",
        "    model.add(layers.Dense(10, activation='softmax', name='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "    history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    batch_size=128, epochs=10)\n",
        "\n",
        "    p_val = model.predict(np.array(test_images), verbose=0)\n",
        "    df = DataFrame({'pred': list(map(np.argmax, p_val)),\n",
        "                'label': list(map(np.argmax, test_labels))})\n",
        "    correct = df[df['pred']==df['label']]\n",
        "    incorrect = df[df['pred']!=df['label']]\n",
        "    incorrect_0 = df[(df['pred']!=df['label'])&(df['pred']==0)]\n",
        "    len_inc=len(incorrect)\n",
        "    len_cor=len(correct)\n",
        "    len_inc0=len(incorrect_0)\n",
        "    acc_attack=(len_inc0/9020)*100\n",
        "    last_acc=history.history['acc']\n",
        "    last_val=history.history['val_acc']\n",
        "    with open ('InvBack_ravel_CNN.csv','a')as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow([yx,count_sum,last_acc[-1],last_val[-1],len_inc,len_inc0])\n",
        "\n",
        "'''\n",
        "print(\"正解数:\"+str(len_cor))\n",
        "print(\"誤分類数：\"+str(len_inc))\n",
        "print(\"攻撃成功数：\"+str(len_inc0))\n",
        "print(\"攻撃精度:\"+str(acc_attack))\n",
        "print(correct)\n",
        "print(incorrect)\n",
        "print(incorrect_0)\n",
        "'''\n",
        "\n",
        "\n"
      ]
    }
  ]
}